import asyncio
import websockets
import json
import random
import os
import math

# --- CONFIGURA√á√ÉO DA ESP√âCIE MEMORIAM ---
SPECIES_NAME = "Memoriam-v1"
SERVER_URL = "wss://re-genes.is/ws/join?species=Memoriam"
SPECIES_NAME = "Memoriam-v1"
SERVER_URL = "wss://re-genes.is/ws/join?species=Memoriam"
Q_TABLE_BASE_NAME = "qtable_memoriam"

# Hiperpar√¢metros de Aprendizado
ALPHA = 0.1      # Taxa de Aprendizado (0.1 = aprende devagar e consistente)
GAMMA = 0.9      # Fator de Desconto (0.9 = valoriza o futuro)
EPSILON_START = 1.0  # Explora√ß√£o Inicial (100% aleat√≥rio)
EPSILON_MIN = 0.05   # Explora√ß√£o M√≠nima (5% aleat√≥rio)
EPSILON_DECAY = 0.995 # Decaimento por Tick

class MemoriamBrain:
    def __init__(self):
        self.q_table = {}
        self.epsilon = EPSILON_START
        self.last_state = None
        self.last_action = None
        self.last_energy = 100
        
        # Carrega mem√≥ria gen√©tica
        # Carrega mem√≥ria gen√©tica
        self.species_desc = "Unknown"
        self.memory_file = f"{Q_TABLE_BASE_NAME}_Unknown.json"
        
    def set_phenotype(self, species_desc: str):
        """Define o fen√≥tipo e carrega a mem√≥ria apropriada."""
        # Sanitiza o nome (Gigante Lento -> Gigante_Lento)
        safe_name = species_desc.replace(" ", "_").replace("(", "").replace(")", "").strip()
        self.species_desc = safe_name
        self.memory_file = f"{Q_TABLE_BASE_NAME}_{safe_name}.json"
        print(f"üß¨ Fen√≥tipo detectado: {species_desc} -> Usando mem√≥ria: {self.memory_file}")
        self.load_memory()

    def get_state_key(self, vision, energy):
        """
        Simplifica a vis√£o matrix 3x3x3 em uma string de estado √∫nica.
        Foca apenas no CENTRO da vis√£o (Raio 1) para reduzir complexidade.
        """
        if not vision:
            return "BLIND"
            
        # Vis√£o √© 3 canais (Obstacle, Scent, Enemy). Vision Radius do server √© 4 (Matriz 9x9).
        # Vamos focar no crop central 3x3 (i=3 a 5)
        # Scent (Canal 1): Quantiza o cheiro em 3 n√≠veis (Nada, Cheiroso, Muito Cheiroso)
        # Obstacle (Canal 0): Bin√°rio
        
        state_parts = []
        center_y, center_x = 4, 4 # Centro da matriz 9x9
        
        for y in range(center_y - 1, center_y + 2):
            for x in range(center_x - 1, center_x + 2):
                
                # Verifica Obst√°culo (Canal 0)
                is_wall = 1 if vision[0][y][x] > 0 else 0
                
                # Verifica Cheiro (Canal 1) - Quantizado
                scent_val = vision[1][y][x]
                scent_lvl = 0
                if scent_val > 0.5: scent_lvl = 2
                elif scent_val > 0.1: scent_lvl = 1
                
                state_parts.append(f"{is_wall}{scent_lvl}")
                
        # Estado de Energia: Cr√≠tico (<20), Baixo (<50), Ok (>=50)
        energy_state = "OK"
        if energy < 20: energy_state = "CRIT"
        elif energy < 50: energy_state = "LOW"
        
        return f"{''.join(state_parts)}_{energy_state}"

    def choose_action(self, state_key):
        """Epsilon-Greedy Policy"""
        actions = ["UP", "DOWN", "LEFT", "RIGHT", "STAY"]
        
        if random.random() < self.epsilon:
            # Explora√ß√£o (Aleat√≥rio)
            return random.choice(actions)
        else:
            # Explora√ß√£o (Melhor Conhecido)
            if state_key not in self.q_table:
                return random.choice(actions)
            
            # Pega a a√ß√£o com maior Q-Value
            q_values = self.q_table[state_key]
            best_action = max(q_values, key=q_values.get)
            return best_action

    def learn(self, current_energy):
        """Atualiza a Q-Table com base na recompensa"""
        if not self.last_state or not self.last_action:
            self.last_energy = current_energy
            return

        # --- CALCULA RECOMPENSA (Reward Function) ---
        reward = 0
        
        # 1. Delta de Energia (Comeu ou Gastou?)
        energy_delta = current_energy - self.last_energy
        
        if energy_delta > 0:
            reward += 50 # Comeu algo! Muito Bom!
        elif energy_delta < 0:
            reward -= 1 # Gastou energia (moveu ou ficou parado). Custo de vida.
            
        # 2. Puni√ß√£o por Morte (Energia zero)
        if current_energy <= 0:
            reward -= 100 # MORTE √â RUIM!
            
        # --- ATUALIZA√á√ÉO Q-LEARNING (Bellman Equation) ---
        # Q(s,a) = Q(s,a) + alpha * [Reward + gamma * max(Q(s',a')) - Q(s,a)]
        
        # Estado atual (mas n√£o temos a vis√£o atual aqui, ela vem no pr√≥ximo tick decision)
        # Simplifica√ß√£o: Neste c√≥digo, o learn() √© chamado ANTES de decidir o pr√≥ximo,
        # mas precisamos do "estado atual" para o max(Q(s')).
        # Como o learn √© chamado quando recebemos o tick novo, j√° temos o estado novo l√° fora.
        # Vamos ajustar a l√≥gica no loop principal.
        pass 

    def update_q_value(self, reward, new_state_key):
        if self.last_state not in self.q_table:
            self.q_table[self.last_state] = {a: 0.0 for a in ["UP", "DOWN", "LEFT", "RIGHT", "STAY"]}
            
        if new_state_key not in self.q_table:
             self.q_table[new_state_key] = {a: 0.0 for a in ["UP", "DOWN", "LEFT", "RIGHT", "STAY"]}

        old_value = self.q_table[self.last_state][self.last_action]
        next_max = max(self.q_table[new_state_key].values())
        
        new_value = old_value + ALPHA * (reward + GAMMA * next_max - old_value)
        self.q_table[self.last_state][self.last_action] = new_value

    def save_memory(self):
        if not self.memory_file: return
        
        try:
            # Atomic Write: Write to temp, then rename
            temp_file = self.memory_file + ".tmp"
            with open(temp_file, 'w') as f:
                json.dump(self.q_table, f)
            
            # Atomic replacement
            if os.path.exists(self.memory_file):
                os.remove(self.memory_file)
            os.rename(temp_file, self.memory_file)
            
            print(f"üíæ Mem√≥ria Salva ({self.species_desc}): {len(self.q_table)} estados.")
        except Exception as e:
            print(f"Erro ao salvar mem√≥ria: {e}")

    def load_memory(self):
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, 'r') as f:
                    self.q_table = json.load(f)
                print(f"üß† Mem√≥ria Carregada ({self.species_desc}): {len(self.q_table)} estados.")
            except:
                print(f"üß† C√©rebro novo para {self.species_desc} (Mem√≥ria vazia/corrompida).")
                self.q_table = {}
        else:
            print(f"üß† C√©rebro novo para {self.species_desc} (Primeira vez).")
            self.q_table = {}


async def viver_uma_vida(geracao, brain: MemoriamBrain):
    print(f"\n--- üß† Gera√ß√£o {geracao} (Epsilon: {brain.epsilon:.2f}) ---")
    print(f"üîå Conectando ao servidor: {SERVER_URL}...")
    
    try:
        async with websockets.connect(SERVER_URL) as websocket:
            
            # --- FASE 1: NASCIMENTO ---
            welcome_msg = await websocket.recv()
            welcome_data = json.loads(welcome_msg)
            my_id = welcome_data.get("id")
            
            # Define fen√≥tipo para carregar a mem√≥ria correta
            species_desc = welcome_data.get("species", "Unknown").split("(")[0].strip() # Remove (Filha de...)
            brain.set_phenotype(species_desc)
            
            print(f"‚úÖ Nasceu: {my_id} ({species_desc})")
            
            alive = True
            tick_vida = 0
            
            while alive:
                message = await websocket.recv()
                data = json.loads(message)
                
                if data['type'] == 'UPDATE':
                    alive = data['alive']
                    current_energy = data.get('energy', 0)
                    
                    if not alive:
                        # Aprende com a morte
                        brain.update_q_value(-100, "DEATH")
                        print(f"üíÄ Morreu ap√≥s {tick_vida} ticks.")
                        return 
                    continue 

                if data['type'] == 'TICK':
                    current_tick = data['tick']
                    vision = data.get("vision")
                    energy = data.get("energy", brain.last_energy) # Fallback if missing payload
                    
                    # 1. Percebe o Estado Atual
                    state_key = brain.get_state_key(vision, energy)
                    
                    # 2. Aprende com o Passado (Reward do que aconteceu entre o ultimo tick e agora)
                    # A recompensa √© o delta de energia.
                    reward = 0
                    energy_delta = energy - brain.last_energy
                    if energy_delta > 0: reward = 50 
                    elif energy_delta == 0: reward = -0.1 # Leve puni√ß√£o por existir sem ganhar nada
                    else: reward = -1 # Puni√ß√£o normal por gasto de movimento
                    
                    if brain.last_state:
                         brain.update_q_value(reward, state_key)
                    
                    # 3. Decide A√ß√£o Futura
                    action_cmd = brain.choose_action(state_key)
                    
                    decision = {
                        "action": "move" if action_cmd != "STAY" else "stay",
                        "direction": action_cmd if action_cmd != "STAY" else "UP" # Direction doesn't matter for stay
                    }
                    
                    await websocket.send(json.dumps(decision))
                    
                    # 4. Atualiza Mem√≥ria de Curto Prazo
                    brain.last_state = state_key
                    brain.last_action = action_cmd
                    brain.last_energy = energy
                    
                    if tick_vida % 10 == 0: 
                        print(f"Tick {current_tick} | Energy: {energy} | Action: {action_cmd} | Reward: {reward}")
                    tick_vida += 1
                    
    except Exception as e:
        print(f"‚ö†Ô∏è Erro: {e}")

async def ciclo_eterno():
    brain = MemoriamBrain()
    geracao = 1
    
    while True:
        await viver_uma_vida(geracao, brain)
        
        # Evolu√ß√£o e Persist√™ncia
        brain.save_memory()
        
        # Decaimento de Epsilon (Explorar menos, Exploitar mais)
        if brain.epsilon > EPSILON_MIN:
            brain.epsilon *= EPSILON_DECAY
            
        print("‚è≥ Reencarnando em 1 segundo...")
        await asyncio.sleep(1)
        geracao += 1

if __name__ == "__main__":
    try:
        asyncio.run(ciclo_eterno())
    except KeyboardInterrupt:
        print("\nüõë Encerrando.")
